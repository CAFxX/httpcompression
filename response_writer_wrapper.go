package httpcompression

import (
	"compress/gzip"
	"github.com/CAFxX/httpcompression/contrib/andybalholm/brotli"
	"github.com/CAFxX/httpcompression/contrib/compress/zlib"
	"net/http"
	"sync"
)

const (
	// DefaultMinSize is the default minimum response body size for which we enable compression.
	//
	// 200 is a somewhat arbitrary number; in experiments compressing short text/markup-like sequences
	// with different compressors we saw that sequences shorter that ~180 the output generated by the
	// compressor would sometime be larger than the input.
	// This default may change between versions.
	// In general there can be no one-size-fits-all value: you will want to measure if a different
	// minimum size improves end-to-end performance for your workloads.
	DefaultMinSize = 200
)

type codings map[string]float64

type ResponseWriterWrapper struct {
	config     config
	bufPool    sync.Pool
	writerPool sync.Pool
}

func NewResponseWriterWrapper(opts ...Option) (*ResponseWriterWrapper, error) {
	wrapper := ResponseWriterWrapper{
		config: config{
			prefer:     PreferServer,
			compressor: comps{},
		},
	}

	wrapper.bufPool.New = func() interface{} {
		return &[]byte{}
	}
	wrapper.writerPool.New = func() interface{} {
		return &compressWriter{
			config: &wrapper.config,
			pool:   &wrapper.bufPool,
		}
	}

	for _, o := range opts {
		err := o(&wrapper.config)
		if err != nil {
			return nil, err
		}
	}

	return &wrapper, nil
}

// NewDefaultResponseWriterWrapper is like NewResponseWriterWrapper, but it includes sane
// defaults for general usage.
// Currently, the defaults enable gzip and brotli compression, and set a minimum body size
// of 200 bytes.
// The provided opts override the defaults.
// The defaults are not guaranteed to remain constant over time: if you want to avoid this
// use NewResponseWriterWrapper directly.
func NewDefaultResponseWriterWrapper(opts ...Option) (*ResponseWriterWrapper, error) {
	defaults := []Option{
		DeflateCompressionLevel(zlib.DefaultCompression),
		GzipCompressionLevel(gzip.DefaultCompression),
		BrotliCompressionLevel(brotli.DefaultCompression),
		defaultZstandardCompressor(),
		MinSize(DefaultMinSize),
	}
	opts = append(defaults, opts...)
	return NewResponseWriterWrapper(opts...)
}

// Wrap wraps the given http.ResponseWriter into a new instance
// with is using compressor (if supported and requested).
//
// The return parameter wrapped is true the http.ResponseWriter
// was wrapped and will be potentially response. Otherwise, it
// will be false and the original given http.ResponseWriter will
// be returned.
//
// Important: Finalizer() must be called *always*, as this will
// in turn Close() the compressor. This is important because
// it is guaranteed by the CompressorProvider interface, and
// because some compressors may be implemented via cgo, and they
// may rely on Close() being called to release memory resources.
func (r *ResponseWriterWrapper) Wrap(rw http.ResponseWriter, req *http.Request) (_ http.ResponseWriter, wrapped bool, _ Finalizer, _ error) {
	addVaryHeader(rw.Header(), acceptEncoding)

	accept := parseEncodings(req.Header.Values(acceptEncoding))
	common := acceptedCompression(accept, r.config.compressor)
	if len(common) == 0 {
		return rw, false, noopFinalizer, nil
	}

	// We do not handle range requests when compression is used, as the
	// range specified applies to the compressed data, not to the uncompressed one.
	// So we would need to (1) ensure that compressors are deterministic and (2)
	// generate the whole uncompressed response anyway, compress it, and then discard
	// the bits outside the range.
	// Let's keep it simple, and simply ignore completely the range header.
	// We also need to remove the Accept: Range header from any response that is
	// compressed; this is done in the ResponseWriter.
	// See https://github.com/nytimes/gziphandler/issues/83.
	req.Header.Del(_range)

	gw := r.writerPool.Get().(*compressWriter)
	gw.configure(rw, accept, common)

	if _, ok := rw.(http.CloseNotifier); ok {
		rw = compressWriterWithCloseNotify{gw}
	} else {
		rw = gw
	}

	return rw, true, func() error {
		defer r.writerPool.Put(gw)
		defer gw.clean()
		return gw.Close()
	}, nil
}

// AmountOfCompressors returns the amount of compressors configured at this ResponseWriterWrapper.
func (r *ResponseWriterWrapper) AmountOfCompressors() int {
	return len(r.config.compressor)
}

func (r *ResponseWriterWrapper) getBuffer() *[]byte {
	b := r.bufPool.Get()
	if b == nil {
		var s []byte
		return &s
	}
	return b.(*[]byte)
}

func (r *ResponseWriterWrapper) recycleBuffer(target *[]byte) {
	if target == nil {
		return
	}
	if cap(*target) > maxBuf {
		// If the buffer is too big, let's drop it to avoid
		// keeping huge buffers alive in the pool. In this case
		// we still recycle the pointer to the slice.
		*target = nil
	}
	if len(*target) > 0 {
		// Reset the buffer to zero length.
		*target = (*target)[:0]
	}
	r.bufPool.Put(target)
}

type Finalizer func() error

func noopFinalizer() error { return nil }
